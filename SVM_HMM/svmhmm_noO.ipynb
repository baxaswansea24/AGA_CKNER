{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed48dec1-f49a-4ec3-a184-e3b7fa6b1bd3",
   "metadata": {},
   "source": [
    "# SVM-HMM One Go - without O tag F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0a9213-fdb8-4462-a544-29280da9fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (excluding O): 0.9446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.969     0.960     0.965      2431\n",
      "      B-MISC      0.966     0.918     0.941      1294\n",
      "       B-ORG      0.933     0.927     0.930      1062\n",
      "       B-PER      0.974     0.908     0.940       651\n",
      "       I-PER      0.978     0.927     0.952       614\n",
      "       I-ORG      0.944     0.944     0.944      1259\n",
      "      I-MISC      0.933     0.949     0.941       547\n",
      "       I-LOC      0.932     0.944     0.938       591\n",
      "      B-DATE      0.910     0.910     0.910       670\n",
      "      I-DATE      0.937     0.951     0.944       824\n",
      "\n",
      "   micro avg      0.951     0.938     0.945      9943\n",
      "   macro avg      0.948     0.934     0.940      9943\n",
      "weighted avg      0.952     0.938     0.945      9943\n",
      "\n",
      "مەهدی -> B-PER\n",
      "ئۆزدەمیر -> I-PER\n",
      "لە -> O\n",
      "بارۆی -> B-ORG\n",
      "ئامەد -> I-ORG\n",
      "رایگەیاند -> O\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import joblib\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "def load_data(filepath):\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        sentence = []\n",
    "        tag_seq = []\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    tags.append(tag_seq)\n",
    "                    sentence = []\n",
    "                    tag_seq = []\n",
    "            else:\n",
    "                word, tag = line.split()\n",
    "                sentence.append(word)\n",
    "                tag_seq.append(tag)\n",
    "        if sentence:  # Add the last sentence if there's no trailing newline\n",
    "            sentences.append(sentence)\n",
    "            tags.append(tag_seq)\n",
    "    return sentences, tags\n",
    "\n",
    "# Replace 'your_dataset.txt' with the path to your dataset file\n",
    "sentences, tags = load_data('wlina_bd.txt')\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(sentences, tags, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction functions\n",
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "    \n",
    "    features = {\n",
    "        'word': word,\n",
    "        'is_first': i == 0,\n",
    "        'is_last': i == len(sent) - 1,\n",
    "        'is_capitalized': word[0].upper() == word[0],\n",
    "        'is_all_caps': word.upper() == word,\n",
    "        'is_all_lower': word.lower() == word,\n",
    "        'prefix-1': word[0],\n",
    "        'prefix-2': word[:2],\n",
    "        'prefix-3': word[:3],\n",
    "        'suffix-1': word[-1],\n",
    "        'suffix-2': word[-2:],\n",
    "        'suffix-3': word[-3:],\n",
    "        'prev_word': '' if i == 0 else sent[i - 1],\n",
    "        'next_word': '' if i == len(sent) - 1 else sent[i + 1],\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "X_train_feats = [sent2features(s) for s in X_train]\n",
    "X_test_feats = [sent2features(s) for s in X_test]\n",
    "\n",
    "# Train the CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "crf.fit(X_train_feats, y_train)\n",
    "\n",
    "# Predict the tags for the test set\n",
    "y_pred = crf.predict(X_test_feats)\n",
    "\n",
    "# Filter out 'O' tag when calculating metrics\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "# Evaluate the performance excluding 'O' tag\n",
    "f1_score = metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)\n",
    "print(f'F1 Score (excluding O): {f1_score:.4f}')\n",
    "\n",
    "# Display classification report excluding 'O' tag\n",
    "report = metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3)\n",
    "print(report)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(crf, 'crf_ner_model_noO.pkl')\n",
    "\n",
    "# Prediction on new text sentence\n",
    "def predict_entities(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    features = [sent2features(tokens)]\n",
    "    prediction = crf.predict(features)[0]\n",
    "    \n",
    "    # Combine tokens and predictions\n",
    "    return list(zip(tokens, prediction))\n",
    "\n",
    "# Example usage\n",
    "new_sentence = \"مەهدی ئۆزدەمیر لە بارۆی ئامەد رایگەیاند\"\n",
    "entities = predict_entities(new_sentence)\n",
    "\n",
    "for word, tag in entities:\n",
    "    print(f\"{word} -> {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf64ccf6-fcb7-4e37-98fd-36ff446c318b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
