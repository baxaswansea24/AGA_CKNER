{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c715f4f3-05cd-44bf-968b-46865609bd3c",
   "metadata": {},
   "source": [
    "# Step 1: Load the Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e731e79-0b14-41d9-994d-3e27a3f88e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_entity_data(file_path):\n",
    "    # Load the Excel file\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    \n",
    "    # Read each sheet into a list, assuming the first column contains the data\n",
    "    per_data = xls.parse('PER')['Entity'].tolist()\n",
    "    loc_data = xls.parse('LOC')['Entity'].tolist()\n",
    "    org_data = xls.parse('ORG')['Entity'].tolist()\n",
    "    \n",
    "    return per_data, loc_data, org_data\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'ckner_ec.xlsx'  # Replace with your correct file path\n",
    "per_data, loc_data, org_data = load_entity_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb5d9e-2cc9-418d-bd22-5791add05448",
   "metadata": {},
   "source": [
    "# Step 2: Define the Rule-Based Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9d5fc2-e199-4b3d-a8b4-a67447815964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_person(phrase, per_data):\n",
    "    return phrase in per_data\n",
    "\n",
    "def is_organization(phrase, org_data):\n",
    "    return phrase in org_data\n",
    "\n",
    "def is_location(phrase, loc_data):\n",
    "    return phrase in loc_data\n",
    "\n",
    "def apply_rules_to_text(text, per_data, org_data, loc_data):\n",
    "    tokens = text.split()  # Split the text into words\n",
    "    labels = ['O'] * len(tokens)  # Initialize all labels as 'O'\n",
    "    length = len(tokens)\n",
    "    \n",
    "    # Check for multi-word organizations and locations first\n",
    "    for i in range(length):\n",
    "        for j in range(length, i, -1):\n",
    "            phrase = ' '.join(tokens[i:j])\n",
    "            if is_person(phrase, per_data):\n",
    "                labels[i:j] = ['B-PER'] + ['I-PER'] * (j - i - 1)\n",
    "                break  # Move to the next starting position once matched\n",
    "            elif is_organization(phrase, org_data):\n",
    "                labels[i:j] = ['B-ORG'] + ['I-ORG'] * (j - i - 1)\n",
    "                break\n",
    "            elif is_location(phrase, loc_data):\n",
    "                labels[i:j] = ['B-LOC'] + ['I-LOC'] * (j - i - 1)\n",
    "                break\n",
    "\n",
    "    return list(zip(tokens, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25069e-cdde-4404-8d9a-28a2dff887b8",
   "metadata": {},
   "source": [
    "# Step 3: Apply the Rules to a Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f7e89f-1f50-4308-852f-6f8a710fc7fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('مەهدی', 'O'), ('لە', 'O'), ('نەتەوە', 'B-ORG'), ('یەکگرتووەکان', 'I-ORG'), ('کار', 'O'), ('دەکات', 'O'), ('و', 'O'), ('لە', 'O'), ('سلێمانی', 'B-LOC'), ('و', 'O'), ('کۆمپانیای', 'B-ORG'), ('قەیوان', 'B-ORG'), ('گرووپ', 'I-ORG'), ('و', 'O'), ('کوردستان', 'B-LOC'), ('دەژی', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# Sample text that includes multi-word entities\n",
    "sample_text = \"مەهدی لە نەتەوە یەکگرتووەکان کار دەکات و لە سلێمانی و کۆمپانیای قەیوان گرووپ و کوردستان دەژی\"\n",
    "annotated_text = apply_rules_to_text(sample_text, per_data, org_data, loc_data)\n",
    "print(annotated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4980fea-ec8b-400a-b5b5-efd33eb926df",
   "metadata": {},
   "source": [
    "# Step 4: Save the Rule-Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0eabd65-cc69-424b-ba3f-4c126fec8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_rule_based_model(per_data, org_data, loc_data, filename='rule_based_ner.pkl'):\n",
    "    model_data = {'per_data': per_data, 'org_data': org_data, 'loc_data': loc_data}\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model_data, f)\n",
    "\n",
    "# Save the model\n",
    "save_rule_based_model(per_data, org_data, loc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917a17f-8843-4854-856b-1f2dea321bb4",
   "metadata": {},
   "source": [
    "# Step 5: Load and Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57f187ae-d9af-4500-8faa-321c3a4e8a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rule_based_model(filename='rule_based_ner.pkl'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    return model_data['per_data'], model_data['org_data'], model_data['loc_data']\n",
    "\n",
    "# Load the model\n",
    "per_data, org_data, loc_data = load_rule_based_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c3b5a-192c-491f-b97e-d6773e1f056a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d51d8e-b4e8-43ea-9c3d-36721dd6bf25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467790c-57de-498e-b8e5-50ce9abe1adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "442695b9-0ceb-47ae-89ae-c8743981885f",
   "metadata": {},
   "source": [
    "# FUll Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "903806c2-78f3-407d-953f-14c64177e615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ئاگا', 'B-PER'), ('لە', 'O'), ('نەتەوە', 'B-ORG'), ('یەکگرتووەکان', 'I-ORG'), ('کار', 'O'), ('دەکات', 'O'), ('و', 'O'), ('لە', 'O'), ('کوردستان', 'B-LOC'), ('دەژی', 'O')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Step 1: Load the entity data from the Excel file\n",
    "def load_entity_data(file_path):\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    per_data = xls.parse('PER')['Entity'].tolist()\n",
    "    loc_data = xls.parse('LOC')['Entity'].tolist()\n",
    "    org_data = xls.parse('ORG')['Entity'].tolist()\n",
    "    return per_data, loc_data, org_data\n",
    "\n",
    "# Step 2: Implement the rule-based functions\n",
    "def is_person(phrase, per_data):\n",
    "    return phrase in per_data\n",
    "\n",
    "def is_organization(phrase, org_data):\n",
    "    return phrase in org_data\n",
    "\n",
    "def is_location(phrase, loc_data):\n",
    "    return phrase in loc_data\n",
    "\n",
    "# Step 3: Apply the rules to a given text\n",
    "def apply_rules_to_text(text, per_data, org_data, loc_data):\n",
    "    tokens = text.split()  # Split the text into words\n",
    "    labels = ['O'] * len(tokens)  # Initialize all labels as 'O'\n",
    "    length = len(tokens)\n",
    "    \n",
    "    # Check for multi-word organizations and locations first\n",
    "    for i in range(length):\n",
    "        for j in range(length, i, -1):\n",
    "            phrase = ' '.join(tokens[i:j])\n",
    "            if is_person(phrase, per_data):\n",
    "                labels[i:j] = ['B-PER'] + ['I-PER'] * (j - i - 1)\n",
    "                break  # Move to the next starting position once matched\n",
    "            elif is_organization(phrase, org_data):\n",
    "                labels[i:j] = ['B-ORG'] + ['I-ORG'] * (j - i - 1)\n",
    "                break\n",
    "            elif is_location(phrase, loc_data):\n",
    "                labels[i:j] = ['B-LOC'] + ['I-LOC'] * (j - i - 1)\n",
    "                break\n",
    "\n",
    "    return list(zip(tokens, labels))\n",
    "\n",
    "# Step 4: Save the rule-based model\n",
    "def save_rule_based_model(per_data, org_data, loc_data, filename='rule_based_ner.pkl'):\n",
    "    model_data = {'per_data': per_data, 'org_data': org_data, 'loc_data': loc_data}\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model_data, f)\n",
    "\n",
    "# Step 5: Load the rule-based model\n",
    "def load_rule_based_model(filename='rule_based_ner.pkl'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    return model_data['per_data'], model_data['org_data'], model_data['loc_data']\n",
    "\n",
    "# Example usage\n",
    "file_path = 'ckner_ec.xlsx'  # Replace with your correct file path\n",
    "per_data, loc_data, org_data = load_entity_data(file_path)\n",
    "\n",
    "# Test with a sample Kurdish Sorani text\n",
    "sample_text = \"ئاگا لە نەتەوە یەکگرتووەکان کار دەکات و لە کوردستان دەژی\"\n",
    "annotated_text = apply_rules_to_text(sample_text, per_data, org_data, loc_data)\n",
    "print(annotated_text)\n",
    "\n",
    "# Save the model\n",
    "save_rule_based_model(per_data, org_data, loc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663b66c4-6b82-417e-a160-c8ac5eebbf74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
