{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6821fbf8-b6c3-4df4-a029-d069f1761b85",
   "metadata": {},
   "source": [
    "# Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "516a7243-570f-4cba-ad13-cbf71c17a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "    \n",
    "    features = {\n",
    "        'word': word,\n",
    "        'is_first': i == 0,\n",
    "        'is_last': i == len(sent) - 1,\n",
    "        'is_capitalized': word[0].upper() == word[0],\n",
    "        'is_all_caps': word.upper() == word,\n",
    "        'is_all_lower': word.lower() == word,\n",
    "        'prefix-1': word[0],\n",
    "        'prefix-2': word[:2],\n",
    "        'prefix-3': word[:3],\n",
    "        'suffix-1': word[-1],\n",
    "        'suffix-2': word[-2:],\n",
    "        'suffix-3': word[-3:],\n",
    "        'prev_word': '' if i == 0 else sent[i - 1],\n",
    "        'next_word': '' if i == len(sent) - 1 else sent[i + 1],\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def extract_features(tokens):\n",
    "    return sent2features(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c22d6fc-0327-4108-a1e5-20aa3ac447a0",
   "metadata": {},
   "source": [
    "# STEP 1: LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f64bb678-a2e6-4044-a114-382ee44982ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the CRF model from a file\n",
    "crf = joblib.load('ckner.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11a5147-cb8e-42e3-b99c-b470f7d7b0ec",
   "metadata": {},
   "source": [
    "# STEP 2: Define Predict Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dffff631-aa2e-438f-b140-30b78384ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    features = [sent2features(tokens)]\n",
    "    prediction = crf.predict(features)[0]  # Use the loaded CRF model to predict\n",
    "    \n",
    "    return list(zip(tokens, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10487d-344e-4a83-9bd7-0ef7ff08f271",
   "metadata": {},
   "source": [
    "# STEP 3: Define Predict Entities Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4da70ae-067b-4791-bde8-c1f462c092ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    features = [sent2features(tokens)]\n",
    "    prediction = crf.predict(features)[0]  # Use the loaded CRF model to predict\n",
    "    \n",
    "    return list(zip(tokens, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97681ea3-63c9-4daf-ad88-f2cdfd9591e0",
   "metadata": {},
   "source": [
    "# STEP 4: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f322682-7d84-46be-9de0-f770b122d6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "مەهدی -> B-PER\n",
      "ئۆزدەمیر -> I-PER\n",
      "لە -> O\n",
      "بارۆی -> B-ORG\n",
      "ئامەد -> I-ORG\n",
      "رایگەیاند -> O\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"مەهدی ئۆزدەمیر لە بارۆی ئامەد رایگەیاند\"\n",
    "entities = predict_entities(new_sentence)\n",
    "\n",
    "for word, tag in entities:\n",
    "    print(f\"{word} -> {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3cac2-0672-4a6a-ac54-1df60a5f8666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7160df5-e8b0-4478-9a1e-754871b1bd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44792db8-9c82-4427-8668-de55b564ffc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5560383-be31-4621-ac3f-37065f81e2af",
   "metadata": {},
   "source": [
    "# Application Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b006b2a9-16ec-4d1c-8133-97bca0720c5b",
   "metadata": {},
   "source": [
    "# STEP 1: Prepare Your Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd32279-8960-4def-b0fa-68b7656995b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bakht\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import joblib\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Load your trained CRF model\n",
    "crf = joblib.load('ckner.pkl')\n",
    "\n",
    "# Ensure nltk's word tokenizer is ready\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d12cb8a-8a41-4dad-9452-723e5e86cdb2",
   "metadata": {},
   "source": [
    "# STEP 2: Define Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df6c61f-b0b9-4146-b94f-ee9f9ace205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i]\n",
    "    \n",
    "    features = {\n",
    "        'word': word,\n",
    "        'is_first': i == 0,\n",
    "        'is_last': i == len(sent) - 1,\n",
    "        'is_capitalized': word[0].upper() == word[0],\n",
    "        'is_all_caps': word.upper() == word,\n",
    "        'is_all_lower': word.lower() == word,\n",
    "        'prefix-1': word[0],\n",
    "        'prefix-2': word[:2],\n",
    "        'prefix-3': word[:3],\n",
    "        'suffix-1': word[-1],\n",
    "        'suffix-2': word[-2:],\n",
    "        'suffix-3': word[-3:],\n",
    "        'prev_word': '' if i == 0 else sent[i - 1],\n",
    "        'next_word': '' if i == len(sent) - 1 else sent[i + 1],\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0149c2-25fc-489d-890a-71bdf42ffbab",
   "metadata": {},
   "source": [
    "# STEP 3: Define the Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d8c92fb-4351-4d33-81bc-7d8a30b44ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entities(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    features = [sent2features(tokens)]\n",
    "    prediction = crf.predict(features)[0]\n",
    "    return list(zip(tokens, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfdb8be-de97-4f8b-834d-f92c663b92f1",
   "metadata": {},
   "source": [
    "# STEP 4: Create Interactive Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e41318-a68a-49b2-956b-081b58b6a685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02ba85b233343fc87142839ff07fdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Enter your text here', description='Text:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4705f090a945e789b75c1873297fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Recognize Entities', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ccd0c5f2264708b301cddf98aa133e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Text area for user input\n",
    "text_input = widgets.Textarea(\n",
    "    value='Enter your text here',\n",
    "    placeholder='Type something',\n",
    "    description='Text:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Output area to display the results\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        sentence = text_input.value\n",
    "        entities = predict_entities(sentence)\n",
    "        for word, tag in entities:\n",
    "            print(f\"{word}: {tag}\")\n",
    "\n",
    "# Button to trigger the prediction\n",
    "button = widgets.Button(description=\"Recognize Entities\")\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "# Display the interface\n",
    "display(text_input, button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3e8dd-0bfd-4bef-8ea9-cc9c653a68fd",
   "metadata": {},
   "source": [
    "# STEP 5: Run Voila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768f02b-4a92-4efe-9ad9-c9b460eb32b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
